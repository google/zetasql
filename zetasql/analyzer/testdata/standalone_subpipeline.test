|> WHERE true
--
ERROR: Cannot use a standalone subpipeline because there's no default input table [at 1:1]
|> WHERE true
^
==

[default language_features=NONE,+PIPES,+PIPE_DESCRIBE,+PIPE_STATIC_DESCRIBE,+PIPE_FORK,+PIPE_TEE,+PIPE_EXPORT_DATA]
|> WHERE true
--
ERROR: Cannot use a standalone subpipeline because there's no default input table [at 1:1]
|> WHERE true
^
==

# Java AnalyzerOptions don't support passing the default table.
[default no_java]
[default default_table_for_subpipeline_stmt=KeyValue]
# We can still do a non-subpipline statement even if the subpipeline
# input table option is set.
FROM EnumTable;
--
QueryStmt
+-output_column_list=
| +-EnumTable.key#1 AS key [INT32]
| +-EnumTable.TestEnum#2 AS TestEnum [ENUM<zetasql_test__.TestEnum>]
| +-EnumTable.AnotherTestEnum#3 AS AnotherTestEnum [ENUM<zetasql_test__.AnotherTestEnum>]
+-query=
  +-TableScan(column_list=EnumTable.[key#1, TestEnum#2, AnotherTestEnum#3], table=EnumTable, column_index_list=[0, 1, 2])
==

# For this query, we show just the REWRITE_SUBPIPELINE_STMT rewrite,
# which rewrites this to ResolvedGeneralizedQueryStmt.
# For the rest, we just show the final rewrite output, which includes
# rewriting that to statements like ResolvedQueryStmt.
[default enabled_ast_rewrites=DEFAULTS]
[enabled_ast_rewrites=NONE,+SUBPIPELINE_STMT]
[default no_run_sqlbuilder]  # TODO Subpipelines don't work yet.
|> where true
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-FilterScan
|       +-column_list=KeyValue.[Key#1, Value#2]
|       +-input_scan=
|       | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|       +-filter_expr=
|         +-Literal(type=BOOL, value=true)
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValue.Key#1 AS Key [INT64]
      +-KeyValue.Value#2 AS Value [STRING]


[REWRITTEN AST]
GeneralizedQueryStmt
+-output_schema=
| +-OutputSchema
|   +-output_column_list=
|     +-KeyValue.Key#1 AS Key [INT64]
|     +-KeyValue.Value#2 AS Value [STRING]
+-query=
  +-FilterScan
    +-column_list=KeyValue.[Key#1, Value#2]
    +-input_scan=
    | +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
    +-filter_expr=
      +-Literal(type=BOOL, value=true)
==

|> select key+1, value
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-ProjectScan
|       +-column_list=[$pipe_select.$col1#3, KeyValue.Value#2]
|       +-expr_list=
|       | +-$col1#3 :=
|       |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
|       |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
|       |     +-Literal(type=INT64, value=1)
|       +-input_scan=
|         +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-$pipe_select.$col1#3 AS `$col1` [INT64]
      +-KeyValue.Value#2 AS value [STRING]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-$pipe_select.$col1#3 AS `$col1` [INT64]
| +-KeyValue.Value#2 AS value [STRING]
+-query=
  +-ProjectScan
    +-column_list=[$pipe_select.$col1#3, KeyValue.Value#2]
    +-expr_list=
    | +-$col1#3 :=
    |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
    |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
    |     +-Literal(type=INT64, value=1)
    +-input_scan=
      +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
==

# Prune one column from the TableScan.
|> select value
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=[KeyValue.Value#2], table=KeyValue, column_index_list=[1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-ProjectScan
|       +-column_list=[KeyValue.Value#2]
|       +-input_scan=
|         +-SubpipelineInputScan(column_list=[KeyValue.Value#2])
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValue.Value#2 AS value [STRING]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-KeyValue.Value#2 AS value [STRING]
+-query=
  +-ProjectScan
    +-column_list=[KeyValue.Value#2]
    +-input_scan=
      +-TableScan(column_list=[KeyValue.Value#2], table=KeyValue, column_index_list=[1], alias="KeyValue")
==

# Prune all the columns from the TableScan.
|> select 123
--
SubpipelineStmt
+-table_scan=
| +-TableScan(table=KeyValue, alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-ProjectScan
|       +-column_list=[$pipe_select.$col1#3]
|       +-expr_list=
|       | +-$col1#3 := Literal(type=INT64, value=123)
|       +-input_scan=
|         +-SubpipelineInputScan
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-$pipe_select.$col1#3 AS `$col1` [INT64]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-$pipe_select.$col1#3 AS `$col1` [INT64]
+-query=
  +-ProjectScan
    +-column_list=[$pipe_select.$col1#3]
    +-expr_list=
    | +-$col1#3 := Literal(type=INT64, value=123)
    +-input_scan=
      +-TableScan(table=KeyValue, alias="KeyValue")
==

# We show the full rewrite including DESCRIBE once, but exclude that
# rewrite for other queries because it's verbose and unrelated.
|> DESCRIBE
--
SubpipelineStmt
+-table_scan=
| +-TableScan(table=KeyValue, alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-DescribeScan
|       +-column_list=[$pipe_describe.Describe#3]
|       +-input_scan=
|       | +-SubpipelineInputScan
|       +-describe_expr=
|         +-Describe#3 := Literal(type=STRING, value="**Columns**:\nTable Alias  Column Name  Type\n-----------  -----------  ------\nKeyValue     Key          INT64\nKeyValue     Value        STRING\n\n**Table Aliases**:\nTable Alias  Columns\n-----------  ----------\nKeyValue     Key, Value\n")
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-$pipe_describe.Describe#3 AS Describe [STRING]

[DESCRIBE output]
**Columns**:
Table Alias  Column Name  Type
\-----------  -----------  ------
KeyValue     Key          INT64
KeyValue     Value        STRING

**Table Aliases**:
Table Alias  Columns
\-----------  ----------
KeyValue     Key, Value



[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-$pipe_describe.Describe#3 AS Describe [STRING]
+-query=
  +-SetOperationScan
    +-column_list=[$pipe_describe.Describe#3]
    +-op_type=UNION_ALL
    +-input_item_list=
      +-SetOperationItem
      | +-scan=
      | | +-ProjectScan
      | |   +-column_list=[$rewrite_describe.$null#4]
      | |   +-expr_list=
      | |   | +-$null#4 := Literal(type=STRING, value=NULL)
      | |   +-input_scan=
      | |     +-FilterScan
      | |       +-input_scan=
      | |       | +-TableScan(table=KeyValue, alias="KeyValue")
      | |       +-filter_expr=
      | |         +-Literal(type=BOOL, value=false)
      | +-output_column_list=[$rewrite_describe.$null#4]
      +-SetOperationItem
        +-scan=
        | +-ProjectScan
        |   +-column_list=[$rewrite_describe.$describe#5]
        |   +-expr_list=
        |   | +-$describe#5 := Literal(type=STRING, value="**Columns**:\nTable Alias  Column Name  Type\n-----------  -----------  ------\nKeyValue     Key          INT64\nKeyValue     Value        STRING\n\n**Table Aliases**:\nTable Alias  Columns\n-----------  ----------\nKeyValue     Key, Value\n")
        |   +-input_scan=
        |     +-SingleRowScan
        +-output_column_list=[$rewrite_describe.$describe#5]
==

# We see the input table schema, including pseudo-columns and a range variable.
# Rewrites for DESCRIBE excluded after the first one because they are verbose.
[default_table_for_subpipeline_stmt=EnumTable]
[enabled_ast_rewrites=NONE]
|> STATIC_DESCRIBE
|> WHERE EnumTable.key = 1
|> DESCRIBE
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=[EnumTable.key#1], table=EnumTable, column_index_list=[0], alias="EnumTable")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-DescribeScan
|       +-column_list=[$pipe_describe.Describe#6]
|       +-input_scan=
|       | +-FilterScan
|       |   +-column_list=[EnumTable.key#1]
|       |   +-input_scan=
|       |   | +-StaticDescribeScan
|       |   |   +-column_list=[EnumTable.key#1]
|       |   |   +-describe_text=
|       |   |   |   """
|       |   |   |   NameList:
|       |   |   |     key INT32 EnumTable.key#1
|       |   |   |     TestEnum zetasql_test__.TestEnum EnumTable.TestEnum#2
|       |   |   |     AnotherTestEnum zetasql_test__.AnotherTestEnum EnumTable.AnotherTestEnum#3
|       |   |   |   NameScope:
|       |   |   |     Names:
|       |   |   |       AnotherTestEnum -> zetasql_test__.AnotherTestEnum (EnumTable.AnotherTestEnum#3) (implicit)
|       |   |   |       Filename -> STRING (EnumTable.Filename#4) (implicit) (pseudo-column)
|       |   |   |       RowId -> BYTES (EnumTable.RowId#5) (implicit) (pseudo-column)
|       |   |   |       TestEnum -> zetasql_test__.TestEnum (EnumTable.TestEnum#2) (implicit)
|       |   |   |       key -> INT32 (EnumTable.key#1) (implicit)
|       |   |   |     Range variables:
|       |   |   |       EnumTable -> RANGE_VARIABLE<key,TestEnum,AnotherTestEnum>
|       |   |   |   """
|       |   |   +-input_scan=
|       |   |     +-SubpipelineInputScan(column_list=[EnumTable.key#1])
|       |   +-filter_expr=
|       |     +-FunctionCall(ZetaSQL:$equal(INT32, INT32) -> BOOL)
|       |       +-ColumnRef(type=INT32, column=EnumTable.key#1)
|       |       +-Literal(type=INT32, value=1)
|       +-describe_expr=
|         +-Describe#6 := Literal(type=STRING, value="**Columns**:\nTable Alias  Column Name      Type\n-----------  ---------------  ------------------------------\nEnumTable    key              INT32\nEnumTable    TestEnum         zetasql_test__.TestEnum\nEnumTable    AnotherTestEnum  zetasql_test__.AnotherTestEnum\n\n**Pseudo-columns**:\nTable Alias  Column Name  Type\n-----------  -----------  ------\nEnumTable    Filename     STRING\nEnumTable    RowId        BYTES\n\n**Table Aliases**:\nTable Alias  Columns                         Pseudo-columns\n-----------  ------------------------------  ---------------\nEnumTable    key, TestEnum, AnotherTestEnum  Filename, RowId\n")
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-$pipe_describe.Describe#6 AS Describe [STRING]

[DESCRIBE output]
**Columns**:
Table Alias  Column Name      Type
\-----------  ---------------  ------------------------------
EnumTable    key              INT32
EnumTable    TestEnum         zetasql_test__.TestEnum
EnumTable    AnotherTestEnum  zetasql_test__.AnotherTestEnum

**Pseudo-columns**:
Table Alias  Column Name  Type
\-----------  -----------  ------
EnumTable    Filename     STRING
EnumTable    RowId        BYTES

**Table Aliases**:
Table Alias  Columns                         Pseudo-columns
\-----------  ------------------------------  ---------------
EnumTable    key, TestEnum, AnotherTestEnum  Filename, RowId
\
==

# We see the input table schema, including pseudo-columns and a range variable,
# for a value table.
# Rewrites for DESCRIBE excluded after the first one because they are verbose.
[default_table_for_subpipeline_stmt=TestExtraValueTable]
[enabled_ast_rewrites=NONE]
|> STATIC_DESCRIBE
|> WHERE filename = 'abc'
|> WHERE TestExtraValueTable.filename = 'abc'
|> DESCRIBE
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=[TestExtraValueTable.Filename#2], table=TestExtraValueTable, column_index_list=[1], alias="TestExtraValueTable")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-DescribeScan
|       +-column_list=[$pipe_describe.Describe#4]
|       +-input_scan=
|       | +-FilterScan
|       |   +-column_list=[TestExtraValueTable.Filename#2]
|       |   +-input_scan=
|       |   | +-FilterScan
|       |   |   +-column_list=[TestExtraValueTable.Filename#2]
|       |   |   +-input_scan=
|       |   |   | +-StaticDescribeScan
|       |   |   |   +-column_list=[TestExtraValueTable.Filename#2]
|       |   |   |   +-describe_text=
|       |   |   |   |   """
|       |   |   |   |   NameList (is_value_table = true):
|       |   |   |   |     TestExtraValueTable zetasql_test__.TestExtraPB TestExtraValueTable.value#1 (value table)
|       |   |   |   |   NameScope:
|       |   |   |   |     Names:
|       |   |   |   |       Filename -> STRING (TestExtraValueTable.Filename#2) (implicit) (pseudo-column)
|       |   |   |   |       RowId -> BYTES (TestExtraValueTable.RowId#3) (implicit) (pseudo-column)
|       |   |   |   |     Range variables:
|       |   |   |   |       TestExtraValueTable -> RANGE_VARIABLE<$value>
|       |   |   |   |     Value table columns:
|       |   |   |   |       TestExtraValueTable.value#1
|       |   |   |   |   """
|       |   |   |   +-input_scan=
|       |   |   |     +-SubpipelineInputScan(column_list=[TestExtraValueTable.Filename#2])
|       |   |   +-filter_expr=
|       |   |     +-FunctionCall(ZetaSQL:$equal(STRING, STRING) -> BOOL)
|       |   |       +-ColumnRef(type=STRING, column=TestExtraValueTable.Filename#2)
|       |   |       +-Literal(type=STRING, value="abc")
|       |   +-filter_expr=
|       |     +-FunctionCall(ZetaSQL:$equal(STRING, STRING) -> BOOL)
|       |       +-ColumnRef(type=STRING, column=TestExtraValueTable.Filename#2)
|       |       +-Literal(type=STRING, value="abc")
|       +-describe_expr=
|         +-Describe#4 := Literal(type=STRING, value="**Columns**:\nTable Alias          Column Name  Type\n-------------------  -----------  --------------------------\nTestExtraValueTable  <value>      zetasql_test__.TestExtraPB\n\n**Pseudo-columns**:\nTable Alias          Column Name  Type\n-------------------  -----------  ------\nTestExtraValueTable  Filename     STRING\nTestExtraValueTable  RowId        BYTES\n\n**Table Aliases**:\nTable Alias          Columns  Pseudo-columns\n-------------------  -------  ---------------\nTestExtraValueTable  <value>  Filename, RowId\n\nResult is a value table.\n")
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-$pipe_describe.Describe#4 AS Describe [STRING]

[DESCRIBE output]
**Columns**:
Table Alias          Column Name  Type
\-------------------  -----------  --------------------------
TestExtraValueTable  <value>      zetasql_test__.TestExtraPB

**Pseudo-columns**:
Table Alias          Column Name  Type
\-------------------  -----------  ------
TestExtraValueTable  Filename     STRING
TestExtraValueTable  RowId        BYTES

**Table Aliases**:
Table Alias          Columns  Pseudo-columns
\-------------------  -------  ---------------
TestExtraValueTable  <value>  Filename, RowId

Result is a value table.
\
==

# Output propagates a value table.
[default_table_for_subpipeline_stmt=TestExtraValueTable]
|> WHERE true
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=[TestExtraValueTable.value#1], table=TestExtraValueTable, column_index_list=[0], alias="TestExtraValueTable")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-FilterScan
|       +-column_list=[TestExtraValueTable.value#1]
|       +-input_scan=
|       | +-SubpipelineInputScan(column_list=[TestExtraValueTable.value#1])
|       +-filter_expr=
|         +-Literal(type=BOOL, value=true)
+-output_schema=
  +-OutputSchema
    +-output_column_list=
    | +-TestExtraValueTable.value#1 AS `$value` [PROTO<zetasql_test__.TestExtraPB>]
    +-is_value_table=TRUE


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-TestExtraValueTable.value#1 AS `$value` [PROTO<zetasql_test__.TestExtraPB>]
+-is_value_table=TRUE
+-query=
  +-FilterScan
    +-column_list=[TestExtraValueTable.value#1]
    +-input_scan=
    | +-TableScan(column_list=[TestExtraValueTable.value#1], table=TestExtraValueTable, column_index_list=[0], alias="TestExtraValueTable")
    +-filter_expr=
      +-Literal(type=BOOL, value=true)
==

# Output can become a value table.
|> SELECT AS STRUCT(key, value, 123)
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-ProjectScan
|       +-column_list=[$make_struct.$struct#4]
|       +-expr_list=
|       | +-$struct#4 :=
|       |   +-MakeStruct
|       |     +-type=STRUCT<STRUCT<INT64, STRING, INT64>>
|       |     +-field_list=
|       |       +-ColumnRef(type=STRUCT<INT64, STRING, INT64>, column=$pipe_select.$col1#3)
|       +-input_scan=
|         +-ProjectScan
|           +-column_list=[$pipe_select.$col1#3]
|           +-expr_list=
|           | +-$col1#3 :=
|           |   +-MakeStruct
|           |     +-type=STRUCT<INT64, STRING, INT64>
|           |     +-field_list=
|           |       +-ColumnRef(type=INT64, column=KeyValue.Key#1)
|           |       +-ColumnRef(type=STRING, column=KeyValue.Value#2)
|           |       +-Literal(type=INT64, value=123)
|           +-input_scan=
|             +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
+-output_schema=
  +-OutputSchema
    +-output_column_list=
    | +-$make_struct.$struct#4 AS `$struct` [STRUCT<STRUCT<INT64, STRING, INT64>>]
    +-is_value_table=TRUE


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-$make_struct.$struct#4 AS `$struct` [STRUCT<STRUCT<INT64, STRING, INT64>>]
+-is_value_table=TRUE
+-query=
  +-ProjectScan
    +-column_list=[$make_struct.$struct#4]
    +-expr_list=
    | +-$struct#4 :=
    |   +-MakeStruct
    |     +-type=STRUCT<STRUCT<INT64, STRING, INT64>>
    |     +-field_list=
    |       +-ColumnRef(type=STRUCT<INT64, STRING, INT64>, column=$pipe_select.$col1#3)
    +-input_scan=
      +-ProjectScan
        +-column_list=[$pipe_select.$col1#3]
        +-expr_list=
        | +-$col1#3 :=
        |   +-MakeStruct
        |     +-type=STRUCT<INT64, STRING, INT64>
        |     +-field_list=
        |       +-ColumnRef(type=INT64, column=KeyValue.Key#1)
        |       +-ColumnRef(type=STRING, column=KeyValue.Value#2)
        |       +-Literal(type=INT64, value=123)
        +-input_scan=
          +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
==

# Output can be ordered.  (The final scan has is_ordered=true.)
|> ORDER BY key
|> LIMIT 2
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-LimitOffsetScan
|       +-column_list=KeyValue.[Key#1, Value#2]
|       +-is_ordered=TRUE
|       +-input_scan=
|       | +-OrderByScan
|       |   +-column_list=KeyValue.[Key#1, Value#2]
|       |   +-is_ordered=TRUE
|       |   +-input_scan=
|       |   | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|       |   +-order_by_item_list=
|       |     +-OrderByItem
|       |       +-column_ref=
|       |         +-ColumnRef(type=INT64, column=KeyValue.Key#1)
|       +-limit=
|         +-Literal(type=INT64, value=2)
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValue.Key#1 AS Key [INT64]
      +-KeyValue.Value#2 AS Value [STRING]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-KeyValue.Key#1 AS Key [INT64]
| +-KeyValue.Value#2 AS Value [STRING]
+-query=
  +-LimitOffsetScan
    +-column_list=KeyValue.[Key#1, Value#2]
    +-is_ordered=TRUE
    +-input_scan=
    | +-OrderByScan
    |   +-column_list=KeyValue.[Key#1, Value#2]
    |   +-is_ordered=TRUE
    |   +-input_scan=
    |   | +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
    |   +-order_by_item_list=
    |     +-OrderByItem
    |       +-column_ref=
    |         +-ColumnRef(type=INT64, column=KeyValue.Key#1)
    +-limit=
      +-Literal(type=INT64, value=2)
==

# Subpipeline joins to another table from the catalog.
|> JOIN EnumTable USING (key)
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-JoinScan
|       +-column_list=[KeyValue.Key#1, KeyValue.Value#2, EnumTable.key#3, EnumTable.TestEnum#4, EnumTable.AnotherTestEnum#5]
|       +-left_scan=
|       | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|       +-right_scan=
|       | +-TableScan(column_list=EnumTable.[key#3, TestEnum#4, AnotherTestEnum#5], table=EnumTable, column_index_list=[0, 1, 2])
|       +-join_expr=
|       | +-FunctionCall(ZetaSQL:$equal(INT64, INT64) -> BOOL)
|       |   +-ColumnRef(type=INT64, column=KeyValue.Key#1)
|       |   +-Cast(INT32 -> INT64)
|       |     +-ColumnRef(type=INT32, column=EnumTable.key#3)
|       +-has_using=TRUE
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValue.Key#1 AS key [INT64]
      +-KeyValue.Value#2 AS Value [STRING]
      +-EnumTable.TestEnum#4 AS TestEnum [ENUM<zetasql_test__.TestEnum>]
      +-EnumTable.AnotherTestEnum#5 AS AnotherTestEnum [ENUM<zetasql_test__.AnotherTestEnum>]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-KeyValue.Key#1 AS key [INT64]
| +-KeyValue.Value#2 AS Value [STRING]
| +-EnumTable.TestEnum#4 AS TestEnum [ENUM<zetasql_test__.TestEnum>]
| +-EnumTable.AnotherTestEnum#5 AS AnotherTestEnum [ENUM<zetasql_test__.AnotherTestEnum>]
+-query=
  +-JoinScan
    +-column_list=[KeyValue.Key#1, KeyValue.Value#2, EnumTable.key#3, EnumTable.TestEnum#4, EnumTable.AnotherTestEnum#5]
    +-left_scan=
    | +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
    +-right_scan=
    | +-TableScan(column_list=EnumTable.[key#3, TestEnum#4, AnotherTestEnum#5], table=EnumTable, column_index_list=[0, 1, 2])
    +-join_expr=
    | +-FunctionCall(ZetaSQL:$equal(INT64, INT64) -> BOOL)
    |   +-ColumnRef(type=INT64, column=KeyValue.Key#1)
    |   +-Cast(INT32 -> INT64)
    |     +-ColumnRef(type=INT32, column=EnumTable.key#3)
    +-has_using=TRUE
==

# Subpipeline has unnest joins on arrays from the pipe input table,
# with or without the range variable.
# These test ExtractTableNamesFromStatement.
[default_table_for_subpipeline_stmt=TestTable]
|> JOIN {{TeSTtAble.|}}KitchenSink.repeated_int32_val
|> JOIN UNNEST(KitchenSink.repeated_int64_val)
--
ALTERNATION GROUP: TeSTtAble.
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=TestTable.[key#1, TestEnum#2, KitchenSink#3], table=TestTable, column_index_list=[0, 1, 2], alias="TestTable")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-ArrayScan
|       +-column_list=[TestTable.key#1, TestTable.TestEnum#2, TestTable.KitchenSink#3, $array.repeated_int32_val#4, $array.$unnest1#5]
|       +-input_scan=
|       | +-ArrayScan
|       |   +-column_list=[TestTable.key#1, TestTable.TestEnum#2, TestTable.KitchenSink#3, $array.repeated_int32_val#4]
|       |   +-input_scan=
|       |   | +-SubpipelineInputScan(column_list=TestTable.[key#1, TestEnum#2, KitchenSink#3])
|       |   +-array_expr_list=
|       |   | +-GetProtoField
|       |   |   +-type=ARRAY<INT32>
|       |   |   +-expr=
|       |   |   | +-ColumnRef(type=PROTO<zetasql_test__.KitchenSinkPB>, column=TestTable.KitchenSink#3)
|       |   |   +-field_descriptor=repeated_int32_val
|       |   |   +-default_value=[]
|       |   +-element_column_list=[$array.repeated_int32_val#4]
|       +-array_expr_list=
|       | +-GetProtoField
|       |   +-type=ARRAY<INT64>
|       |   +-expr=
|       |   | +-ColumnRef(type=PROTO<zetasql_test__.KitchenSinkPB>, column=TestTable.KitchenSink#3)
|       |   +-field_descriptor=repeated_int64_val
|       |   +-default_value=[]
|       +-element_column_list=[$array.$unnest1#5]
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-TestTable.key#1 AS key [INT32]
      +-TestTable.TestEnum#2 AS TestEnum [ENUM<zetasql_test__.TestEnum>]
      +-TestTable.KitchenSink#3 AS KitchenSink [PROTO<zetasql_test__.KitchenSinkPB>]
      +-$array.repeated_int32_val#4 AS repeated_int32_val [INT32]
      +-$array.$unnest1#5 AS `$unnest1` [INT64]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-TestTable.key#1 AS key [INT32]
| +-TestTable.TestEnum#2 AS TestEnum [ENUM<zetasql_test__.TestEnum>]
| +-TestTable.KitchenSink#3 AS KitchenSink [PROTO<zetasql_test__.KitchenSinkPB>]
| +-$array.repeated_int32_val#4 AS repeated_int32_val [INT32]
| +-$array.$unnest1#5 AS `$unnest1` [INT64]
+-query=
  +-ArrayScan
    +-column_list=[TestTable.key#1, TestTable.TestEnum#2, TestTable.KitchenSink#3, $array.repeated_int32_val#4, $array.$unnest1#5]
    +-input_scan=
    | +-ArrayScan
    |   +-column_list=[TestTable.key#1, TestTable.TestEnum#2, TestTable.KitchenSink#3, $array.repeated_int32_val#4]
    |   +-input_scan=
    |   | +-TableScan(column_list=TestTable.[key#1, TestEnum#2, KitchenSink#3], table=TestTable, column_index_list=[0, 1, 2], alias="TestTable")
    |   +-array_expr_list=
    |   | +-GetProtoField
    |   |   +-type=ARRAY<INT32>
    |   |   +-expr=
    |   |   | +-ColumnRef(type=PROTO<zetasql_test__.KitchenSinkPB>, column=TestTable.KitchenSink#3)
    |   |   +-field_descriptor=repeated_int32_val
    |   |   +-default_value=[]
    |   +-element_column_list=[$array.repeated_int32_val#4]
    +-array_expr_list=
    | +-GetProtoField
    |   +-type=ARRAY<INT64>
    |   +-expr=
    |   | +-ColumnRef(type=PROTO<zetasql_test__.KitchenSinkPB>, column=TestTable.KitchenSink#3)
    |   +-field_descriptor=repeated_int64_val
    |   +-default_value=[]
    +-element_column_list=[$array.$unnest1#5]
--
ALTERNATION GROUP: <empty>
--
ERROR: Aliases referenced in the from clause must refer to preceding scans, and cannot refer to columns on those scans. KitchenSink refers to a column and must be qualified with a table name. [at 1:9]
|> JOIN KitchenSink.repeated_int32_val
        ^
==

# Output is a generalized statement without a final table.
|> FORK (
     |> SELECT key+1
    ), (
     |> SELECT value, value
    )
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
  +-Subpipeline
    +-scan=
      +-PipeForkScan
        +-input_scan=
        | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
        +-subpipeline_list=
          +-GeneralizedQuerySubpipeline
          | +-subpipeline=
          | | +-Subpipeline
          | |   +-scan=
          | |     +-ProjectScan
          | |       +-column_list=[$pipe_select.$col1#3]
          | |       +-expr_list=
          | |       | +-$col1#3 :=
          | |       |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
          | |       |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
          | |       |     +-Literal(type=INT64, value=1)
          | |       +-input_scan=
          | |         +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
          | +-output_schema=
          |   +-OutputSchema
          |     +-output_column_list=
          |       +-$pipe_select.$col1#3 AS `$col1` [INT64]
          +-GeneralizedQuerySubpipeline
            +-subpipeline=
            | +-Subpipeline
            |   +-scan=
            |     +-ProjectScan
            |       +-column_list=KeyValue.[Value#2, Value#2]
            |       +-input_scan=
            |         +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
            +-output_schema=
              +-OutputSchema
                +-output_column_list=
                  +-KeyValue.Value#2 AS value [STRING]
                  +-KeyValue.Value#2 AS value [STRING]


[REWRITTEN AST]
MultiStmt
+-statement_list=
  +-CreateWithEntryStmt
  | +-with_entry=
  |   +-WithEntry
  |     +-with_query_name="$fork_cte_1"
  |     +-with_subquery=
  |       +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
  +-QueryStmt
  | +-output_column_list=
  | | +-$pipe_select.$col1#3 AS `$col1` [INT64]
  | +-query=
  |   +-ProjectScan
  |     +-column_list=[$pipe_select.$col1#3]
  |     +-expr_list=
  |     | +-$col1#3 :=
  |     |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
  |     |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
  |     |     +-Literal(type=INT64, value=1)
  |     +-input_scan=
  |       +-WithRefScan(column_list=KeyValue.[Key#1, Value#2], with_query_name="$fork_cte_1")
  +-QueryStmt
    +-output_column_list=
    | +-KeyValue.Value#2 AS value [STRING]
    | +-KeyValue.Value#2 AS value [STRING]
    +-query=
      +-ProjectScan
        +-column_list=KeyValue.[Value#2, Value#2]
        +-input_scan=
          +-WithRefScan(column_list=KeyValue.[Key#1, Value#2], with_query_name="$fork_cte_1")
==

# Output is a generalized statement with a final table.
|> TEE (|> SELECT value)
|> SELECT key+1
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-ProjectScan
|       +-column_list=[$pipe_select.$col1#3]
|       +-expr_list=
|       | +-$col1#3 :=
|       |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
|       |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
|       |     +-Literal(type=INT64, value=1)
|       +-input_scan=
|         +-PipeTeeScan
|           +-column_list=KeyValue.[Key#1, Value#2]
|           +-input_scan=
|           | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|           +-subpipeline_list=
|             +-GeneralizedQuerySubpipeline
|               +-subpipeline=
|               | +-Subpipeline
|               |   +-scan=
|               |     +-ProjectScan
|               |       +-column_list=[KeyValue.Value#2]
|               |       +-input_scan=
|               |         +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|               +-output_schema=
|                 +-OutputSchema
|                   +-output_column_list=
|                     +-KeyValue.Value#2 AS value [STRING]
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-$pipe_select.$col1#3 AS `$col1` [INT64]


[REWRITTEN AST]
MultiStmt
+-statement_list=
  +-CreateWithEntryStmt
  | +-with_entry=
  |   +-WithEntry
  |     +-with_query_name="$tee_cte_1"
  |     +-with_subquery=
  |       +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
  +-QueryStmt
  | +-output_column_list=
  | | +-KeyValue.Value#2 AS value [STRING]
  | +-query=
  |   +-ProjectScan
  |     +-column_list=[KeyValue.Value#2]
  |     +-input_scan=
  |       +-WithRefScan(column_list=KeyValue.[Key#1, Value#2], with_query_name="$tee_cte_1")
  +-QueryStmt
    +-output_column_list=
    | +-$pipe_select.$col1#3 AS `$col1` [INT64]
    +-query=
      +-ProjectScan
        +-column_list=[$pipe_select.$col1#3]
        +-expr_list=
        | +-$col1#3 :=
        |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
        |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
        |     +-Literal(type=INT64, value=1)
        +-input_scan=
          +-WithRefScan(column_list=KeyValue.[Key#1, Value#2], with_query_name="$tee_cte_1")
==


# Output is a non-query statement.
|> EXTEND key+1 AS k1
|> EXPORT DATA OPTIONS(filename="x.csv")
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
  +-Subpipeline
    +-scan=
      +-PipeExportDataScan
        +-export_data_stmt=
          +-ExportDataStmt
            +-option_list=
            | +-filename := Literal(type=STRING, value="x.csv")
            +-output_column_list=
            | +-KeyValue.Key#1 AS Key [INT64]
            | +-KeyValue.Value#2 AS Value [STRING]
            | +-$pipe_extend.k1#3 AS k1 [INT64]
            +-query=
              +-ProjectScan
                +-column_list=[KeyValue.Key#1, KeyValue.Value#2, $pipe_extend.k1#3]
                +-expr_list=
                | +-k1#3 :=
                |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
                |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
                |     +-Literal(type=INT64, value=1)
                +-input_scan=
                  +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])


[REWRITTEN AST]
ExportDataStmt
+-option_list=
| +-filename := Literal(type=STRING, value="x.csv")
+-output_column_list=
| +-KeyValue.Key#1 AS Key [INT64]
| +-KeyValue.Value#2 AS Value [STRING]
| +-$pipe_extend.k1#3 AS k1 [INT64]
+-query=
  +-ProjectScan
    +-column_list=[KeyValue.Key#1, KeyValue.Value#2, $pipe_extend.k1#3]
    +-expr_list=
    | +-k1#3 :=
    |   +-FunctionCall(ZetaSQL:$add(INT64, INT64) -> INT64)
    |     +-ColumnRef(type=INT64, column=KeyValue.Key#1)
    |     +-Literal(type=INT64, value=1)
    +-input_scan=
      +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
==

# Test ExtractTableNames on a table in a nested catalog.
[default_table_for_subpipeline_stmt=nested_catalog.KeyValueNested]
|> WHERE true
--
SubpipelineStmt
+-table_scan=
| +-TableScan(column_list=KeyValueNested.[Key#1, Value#2], table=nested_catalog.KeyValueNested, column_index_list=[0, 1], alias="KeyValueNested")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-FilterScan
|       +-column_list=KeyValueNested.[Key#1, Value#2]
|       +-input_scan=
|       | +-SubpipelineInputScan(column_list=KeyValueNested.[Key#1, Value#2])
|       +-filter_expr=
|         +-Literal(type=BOOL, value=true)
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValueNested.Key#1 AS Key [INT64]
      +-KeyValueNested.Value#2 AS Value [STRING]


[REWRITTEN AST]
QueryStmt
+-output_column_list=
| +-KeyValueNested.Key#1 AS Key [INT64]
| +-KeyValueNested.Value#2 AS Value [STRING]
+-query=
  +-FilterScan
    +-column_list=KeyValueNested.[Key#1, Value#2]
    +-input_scan=
    | +-TableScan(column_list=KeyValueNested.[Key#1, Value#2], table=nested_catalog.KeyValueNested, column_index_list=[0, 1], alias="KeyValueNested")
    +-filter_expr=
      +-Literal(type=BOOL, value=true)
==

# Subpipeline with a hint.
# We show the initial and final rewrite to show the hint propagating
# to both.
[enabled_ast_rewrites={{NONE,+SUBPIPELINE_STMT|DEFAULTS}}]
@{hint=1}
|> WHERE true
--
ALTERNATION GROUP: NONE,+SUBPIPELINE_STMT
--
SubpipelineStmt
+-hint_list=
| +-hint := Literal(type=INT64, value=1)
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-FilterScan
|       +-column_list=KeyValue.[Key#1, Value#2]
|       +-input_scan=
|       | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|       +-filter_expr=
|         +-Literal(type=BOOL, value=true)
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValue.Key#1 AS Key [INT64]
      +-KeyValue.Value#2 AS Value [STRING]


[REWRITTEN AST]
GeneralizedQueryStmt
+-hint_list=
| +-hint := Literal(type=INT64, value=1)
+-output_schema=
| +-OutputSchema
|   +-output_column_list=
|     +-KeyValue.Key#1 AS Key [INT64]
|     +-KeyValue.Value#2 AS Value [STRING]
+-query=
  +-FilterScan
    +-column_list=KeyValue.[Key#1, Value#2]
    +-input_scan=
    | +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
    +-filter_expr=
      +-Literal(type=BOOL, value=true)
--
ALTERNATION GROUP: DEFAULTS
--
SubpipelineStmt
+-hint_list=
| +-hint := Literal(type=INT64, value=1)
+-table_scan=
| +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
+-subpipeline=
| +-Subpipeline
|   +-scan=
|     +-FilterScan
|       +-column_list=KeyValue.[Key#1, Value#2]
|       +-input_scan=
|       | +-SubpipelineInputScan(column_list=KeyValue.[Key#1, Value#2])
|       +-filter_expr=
|         +-Literal(type=BOOL, value=true)
+-output_schema=
  +-OutputSchema
    +-output_column_list=
      +-KeyValue.Key#1 AS Key [INT64]
      +-KeyValue.Value#2 AS Value [STRING]


[REWRITTEN AST]
QueryStmt
+-hint_list=
| +-hint := Literal(type=INT64, value=1)
+-output_column_list=
| +-KeyValue.Key#1 AS Key [INT64]
| +-KeyValue.Value#2 AS Value [STRING]
+-query=
  +-FilterScan
    +-column_list=KeyValue.[Key#1, Value#2]
    +-input_scan=
    | +-TableScan(column_list=KeyValue.[Key#1, Value#2], table=KeyValue, column_index_list=[0, 1], alias="KeyValue")
    +-filter_expr=
      +-Literal(type=BOOL, value=true)
